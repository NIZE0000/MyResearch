{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPM with cats dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import necessary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set image size\n",
    "img_size = 64\n",
    "\n",
    "# Set the path to the dataset\n",
    "dataset_path = 'dataset/cats/'\n",
    "\n",
    "# Set the number of images to transform\n",
    "NUM_IMAGES = 15747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: torch.Size([15747, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Get the list of image filenames\n",
    "image_filenames = os.listdir(dataset_path)\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # convert PIL image to tensor and scales data into [0,1] \n",
    "    # transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), # Scale between [-1, 1] by (input[channel] - mean[channel]) / std[channel]\n",
    "])\n",
    "\n",
    "# Create a list to store the transformed images\n",
    "transformed_images = []\n",
    "\n",
    "# Iterate over the first num_images filenames and transform the corresponding images\n",
    "for i, filename in enumerate(image_filenames[:NUM_IMAGES]):\n",
    "    # Load the image\n",
    "    img_path = os.path.join(dataset_path, filename)\n",
    "    image = Image.open(img_path)\n",
    "\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "\n",
    "    # Append the transformed image to the list\n",
    "    transformed_images.append(transformed_image)\n",
    "\n",
    "# Convert the list of transformed images to a PyTorch tensor\n",
    "transformed_images = torch.stack(transformed_images)\n",
    "\n",
    "print(f'Loaded data: {transformed_images.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# set batch size\n",
    "batch_size = 16\n",
    "\n",
    "data_loader = DataLoader(transformed_images, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "data_iter = iter(data_loader)\n",
    "print(next(data_iter).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the model\n",
    "\n",
    "base on DDPM and unet papers \n",
    "https://arxiv.org/pdf/1505.04597v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ddpm import Diffusion\n",
    "\n",
    "from modules.modules import UNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameter before training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base on the paper\n",
    "LEARNING_RATE = 1e-4  #0.0001\n",
    "# LEARNING_RATE = 1e-5  #0.00001\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "NUM_EPOCHS = 100\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and save weight and log "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training process\n",
    "parameter base on DDPM paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:53:26 - INFO: Starting epoch 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] Batch 984/984 Using Time: 255.3108            Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:57:41 - INFO: Sampling 32 new images....\n",
      "999it [02:46,  6.00it/s]\n",
      "07:00:28 - INFO: Starting epoch 1:\n",
      "07:04:53 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200] Batch 984/984 Using Time: 264.4355            Loss: 0.0032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n",
      "07:07:39 - INFO: Starting epoch 2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200] Batch 984/984 Using Time: 261.2730            Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:12:01 - INFO: Sampling 32 new images....\n",
      "999it [02:45,  6.04it/s]\n",
      "07:14:47 - INFO: Starting epoch 3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200] Batch 984/984 Using Time: 259.9018            Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:19:08 - INFO: Sampling 32 new images....\n",
      "999it [02:45,  6.05it/s]\n",
      "07:21:54 - INFO: Starting epoch 4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200] Batch 984/984 Using Time: 259.8262            Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:26:14 - INFO: Sampling 32 new images....\n",
      "999it [02:44,  6.07it/s]\n",
      "07:28:59 - INFO: Starting epoch 5:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200] Batch 984/984 Using Time: 259.7389            Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:33:19 - INFO: Sampling 32 new images....\n",
      "999it [02:46,  6.02it/s]\n",
      "07:36:06 - INFO: Starting epoch 6:\n",
      "07:40:30 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200] Batch 984/984 Using Time: 264.1362            Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n",
      "07:43:16 - INFO: Starting epoch 7:\n",
      "07:47:38 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200] Batch 984/984 Using Time: 261.2928            Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.01it/s]\n",
      "07:50:25 - INFO: Starting epoch 8:\n",
      "07:54:48 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200] Batch 984/984 Using Time: 262.7316            Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.99it/s]\n",
      "07:57:35 - INFO: Starting epoch 9:\n",
      "08:01:58 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200] Batch 984/984 Using Time: 263.3582            Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:47,  5.96it/s]\n",
      "08:04:47 - INFO: Starting epoch 10:\n",
      "08:09:13 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200] Batch 984/984 Using Time: 265.6976            Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:49,  5.89it/s]\n",
      "08:12:03 - INFO: Starting epoch 11:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200] Batch 984/984 Using Time: 265.9931            Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:16:29 - INFO: Sampling 32 new images....\n",
      "999it [02:50,  5.88it/s]\n",
      "08:19:20 - INFO: Starting epoch 12:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200] Batch 984/984 Using Time: 267.8061            Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:23:48 - INFO: Sampling 32 new images....\n",
      "999it [02:50,  5.85it/s]\n",
      "08:26:40 - INFO: Starting epoch 13:\n",
      "08:31:08 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200] Batch 984/984 Using Time: 268.1376            Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.84it/s]\n",
      "08:34:00 - INFO: Starting epoch 14:\n",
      "08:38:28 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200] Batch 984/984 Using Time: 268.2351            Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.83it/s]\n",
      "08:41:20 - INFO: Starting epoch 15:\n",
      "08:45:49 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/200] Batch 984/984 Using Time: 268.3762            Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.84it/s]\n",
      "08:48:40 - INFO: Starting epoch 16:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/200] Batch 984/984 Using Time: 268.7173            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:53:09 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.83it/s]\n",
      "08:56:01 - INFO: Starting epoch 17:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/200] Batch 984/984 Using Time: 268.7952            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:00:31 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.82it/s]\n",
      "09:03:23 - INFO: Starting epoch 18:\n",
      "09:07:52 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/200] Batch 984/984 Using Time: 268.5911            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.82it/s]\n",
      "09:10:44 - INFO: Starting epoch 19:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200] Batch 984/984 Using Time: 268.7843            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:15:13 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.82it/s]\n",
      "09:18:06 - INFO: Starting epoch 20:\n",
      "09:22:35 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/200] Batch 984/984 Using Time: 269.1617            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.81it/s]\n",
      "09:25:27 - INFO: Starting epoch 21:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/200] Batch 984/984 Using Time: 268.9042            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:29:57 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.82it/s]\n",
      "09:32:49 - INFO: Starting epoch 22:\n",
      "09:37:19 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/200] Batch 984/984 Using Time: 269.4041            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.81it/s]\n",
      "09:40:11 - INFO: Starting epoch 23:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/200] Batch 984/984 Using Time: 269.1417            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:44:41 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.81it/s]\n",
      "09:47:34 - INFO: Starting epoch 24:\n",
      "09:52:03 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/200] Batch 984/984 Using Time: 269.3321            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:52,  5.80it/s]\n",
      "09:54:56 - INFO: Starting epoch 25:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/200] Batch 984/984 Using Time: 269.5257            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:59:26 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.81it/s]\n",
      "10:02:18 - INFO: Starting epoch 26:\n",
      "10:06:48 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/200] Batch 984/984 Using Time: 269.7357            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.81it/s]\n",
      "10:09:40 - INFO: Starting epoch 27:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/200] Batch 984/984 Using Time: 269.1343            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:14:11 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.81it/s]\n",
      "10:17:04 - INFO: Starting epoch 28:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/200] Batch 984/984 Using Time: 269.5513            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:21:34 - INFO: Sampling 32 new images....\n",
      "999it [02:52,  5.80it/s]\n",
      "10:24:27 - INFO: Starting epoch 29:\n",
      "10:28:57 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200] Batch 984/984 Using Time: 270.0007            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:52,  5.79it/s]\n",
      "10:31:50 - INFO: Starting epoch 30:\n",
      "10:36:19 - INFO: Sampling 32 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/200] Batch 984/984 Using Time: 268.9190            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.86it/s]\n",
      "10:39:10 - INFO: Starting epoch 31:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/200] Batch 984/984 Using Time: 266.8575            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:43:38 - INFO: Sampling 32 new images....\n",
      "999it [02:51,  5.81it/s]\n",
      "10:46:30 - INFO: Starting epoch 32:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/200] Batch 984/984 Using Time: 269.8352            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:51:01 - INFO: Sampling 32 new images....\n",
      "999it [02:52,  5.79it/s]\n",
      "10:53:54 - INFO: Starting epoch 33:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, images \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[0;32m---> 28\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     29\u001b[0m     t \u001b[39m=\u001b[39m diffusion\u001b[39m.\u001b[39msample_timesteps(images\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m     x_t, noise \u001b[39m=\u001b[39m diffusion\u001b[39m.\u001b[39mnoise_images(images, t)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "model = UNet().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "mse = nn.MSELoss()\n",
    "diffusion = Diffusion(img_size=IMAGE_SIZE, device=device)\n",
    "writer = SummaryWriter(os.path.join(\"logs/cats\",\"DDPM\"))\n",
    "\n",
    "l = len(data_loader)\n",
    "\n",
    "time_use = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    # Shuffle the dataset at the beginning of each epoch\n",
    "    data_loader = DataLoader(transformed_images, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    lossMean = 0\n",
    "\n",
    "    # logging.info(f\"Starting epoch {epoch}:\")\n",
    "\n",
    "    # use time for time measurement\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, images in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
    "        x_t, noise = diffusion.noise_images(images, t)\n",
    "        predicted_noise = model(x_t, t)\n",
    "        loss = mse(noise, predicted_noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # sum lose\n",
    "        lossMean += loss\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    time_use += epoch_time \n",
    "\n",
    "    epoch_index = epoch+1\n",
    "\n",
    "    # calculate mean value\n",
    "    lossMean = lossMean / len(data_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch_index}/{NUM_EPOCHS}] Batch {batch_idx+1}/{len(data_loader)} Using Time: {epoch_time:.4f}\\\n",
    "            Loss: {lossMean:.4f}\"\n",
    "    )\n",
    "\n",
    "    # tensorboard\n",
    "    writer.add_scalar(\"MSE\", lossMean, global_step=epoch+1)\n",
    "    writer.add_scalar(\"traing time\", time_use, epoch_index)\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(\"weights\", \"cats\", \"DDPM\", f\"{epoch_index}.pt\"))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = diffusion.sample(model, n=32).type(dtype=torch.float32)\n",
    "        img_grid = torchvision.utils.make_grid(x[:32], normalize=True)\n",
    "        writer.add_image(\"All/Generate Images\", img_grid, global_step=epoch_index)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure FID\n",
    "\n",
    "use this implementation: https://github.com/mseitzer/pytorch-fid/tree/master"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define FID measurement function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import re\n",
    "\n",
    "# Create a function to run the FID script\n",
    "def run_fid(real_path, gen_path, epoch):\n",
    "    command = [\"python\", \"-m\", \"pytorch_fid\", real_path, gen_path]\n",
    "\n",
    "    output = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Extract the FID score using regular expressions\n",
    "    output = output.stdout\n",
    "    fid_score_match = re.search(r\"FID:\\s+(\\d+\\.\\d+)\", output)\n",
    "    \n",
    "    if fid_score_match:\n",
    "        fid_score = float(fid_score_match.group(1))\n",
    "        print(\"FID score:\", fid_score)\n",
    "\n",
    "        # Write the FID score to the log file\n",
    "        # gen_log(log_path=\"logs/cats/fid/DCGAN.log\", message=f\"Epoch: {epoch}, FID score: {fid_score}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"FID score not found in the output.\")\n",
    "\n",
    "    return fid_score\n",
    "\n",
    "def FID_measure(model, sample_n=100*8, batch_size=8, device=\"cpu\", real_path=\"dataset/cats/\", gen_path=\"generated_images\", epoch=int):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Create a folder for generated images if it doesn't exist\n",
    "    os.makedirs(gen_path, exist_ok=True)\n",
    "    torch.manual_seed(2023)\n",
    "\n",
    "    # Generate images\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, sample_n, batch_size):\n",
    "            \n",
    "            x = diffusion.sample(model, n=batch_size).type(dtype=torch.float32)\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                save_image(x[j], f\"{gen_path}/{i+j}.png\", normalize=True)\n",
    "        \n",
    "    # Measure FID score between the real and generated images\n",
    "    fid_score = run_fid(real_path, gen_path, epoch)\n",
    "    return fid_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weight of model to measure FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weight( model, weight_path=\"\", index=int):\n",
    "\n",
    "    # Load the saved weights\n",
    "    model.load_state_dict(torch.load(f'{weight_path}/{index}.pt'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:38:55 - INFO: Sampling 64 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [06:15,  2.66it/s]\n",
      "11:45:10 - INFO: Sampling 64 new images....\n",
      "563it [03:33,  2.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m load_weight(model, weight_path\u001b[39m=\u001b[39mdirectory_path, index\u001b[39m=\u001b[39mindex_weight)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m'\u001b[39m,index_weight)\n\u001b[0;32m---> 24\u001b[0m fid_score \u001b[39m=\u001b[39m FID_measure(model, sample_size, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mdevice\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, gen_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgen_image/cats/DDPM/\u001b[39;49m\u001b[39m{\u001b[39;49;00mindex_weight\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m, epoch\u001b[39m=\u001b[39;49mindex_weight)   \n\u001b[1;32m     26\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mMetrics/FID Score\u001b[39m\u001b[39m\"\u001b[39m, fid_score, index_weight)\n",
      "Cell \u001b[0;32mIn[43], line 40\u001b[0m, in \u001b[0;36mFID_measure\u001b[0;34m(model, sample_n, batch_size, device, real_path, gen_path, epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     38\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, sample_n, batch_size):\n\u001b[0;32m---> 40\u001b[0m         x \u001b[39m=\u001b[39m diffusion\u001b[39m.\u001b[39;49msample(model, n\u001b[39m=\u001b[39;49mbatch_size)\u001b[39m.\u001b[39mtype(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     42\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[1;32m     43\u001b[0m             save_image(x[j], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mgen_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39mj\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Workspace/Research/modules/ddpm.py:84\u001b[0m, in \u001b[0;36mDiffusion.sample\u001b[0;34m(self, model, n)\u001b[0m\n\u001b[1;32m     82\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((n, \u001b[39m3\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size))\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mreversed\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise_steps)), position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m---> 84\u001b[0m     t \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39;49mones(n) \u001b[39m*\u001b[39;49m i)\u001b[39m.\u001b[39;49mlong()\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     85\u001b[0m     predicted_noise \u001b[39m=\u001b[39m model(x, t)\n\u001b[1;32m     86\u001b[0m     alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha[t][:, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'logs/cats/DDPM/')\n",
    "\n",
    "# Specify the directory path\n",
    "directory_path = Path('weights/cats/DDPM/')\n",
    "\n",
    "# Get the list of files ending with \".pth\"\n",
    "# file_list = list(directory_path.glob('*.pt'))\n",
    "\n",
    "\n",
    "model = UNet().to(device)\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    index_weight = i+1\n",
    "\n",
    "    load_weight(model, weight_path=directory_path, index=index_weight)\n",
    "\n",
    "    print('Epoch: ',index_weight)\n",
    "    fid_score = FID_measure(model, sample_size, batch_size=64, device=f\"{device}\", gen_path=f\"gen_image/cats/DDPM/{index_weight}/\", epoch=index_weight)   \n",
    "    \n",
    "    writer.add_scalar(\"Metrics/FID Score\", fid_score, index_weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
