{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPM with cats dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import necessary modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set image size\n",
    "img_size = 64\n",
    "\n",
    "# Set the path to the dataset\n",
    "dataset_path = 'dataset/cats/'\n",
    "\n",
    "# Set the number of images to transform\n",
    "NUM_IMAGES = 15747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: torch.Size([15747, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Get the list of image filenames\n",
    "image_filenames = os.listdir(dataset_path)\n",
    "\n",
    "# Define the image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # convert PIL image to tensor and scales data into [0,1] \n",
    "    # transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), # Scale between [-1, 1] by (input[channel] - mean[channel]) / std[channel]\n",
    "])\n",
    "\n",
    "# Create a list to store the transformed images\n",
    "transformed_images = []\n",
    "\n",
    "# Iterate over the first num_images filenames and transform the corresponding images\n",
    "for i, filename in enumerate(image_filenames[:NUM_IMAGES]):\n",
    "    # Load the image\n",
    "    img_path = os.path.join(dataset_path, filename)\n",
    "    image = Image.open(img_path)\n",
    "\n",
    "    # Apply the transformations\n",
    "    transformed_image = transform(image)\n",
    "\n",
    "    # Append the transformed image to the list\n",
    "    transformed_images.append(transformed_image)\n",
    "\n",
    "# Convert the list of transformed images to a PyTorch tensor\n",
    "transformed_images = torch.stack(transformed_images)\n",
    "\n",
    "print(f'Loaded data: {transformed_images.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# set batch size\n",
    "batch_size = 16\n",
    "\n",
    "data_loader = DataLoader(transformed_images, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "data_iter = iter(data_loader)\n",
    "print(next(data_iter).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the model\n",
    "\n",
    "base on DDPM and unet papers \n",
    "https://arxiv.org/pdf/1505.04597v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ddpm import Diffusion\n",
    "\n",
    "from modules.modules import UNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameter before training iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base on the paper\n",
    "LEARNING_RATE = 1e-4  #0.0001\n",
    "# LEARNING_RATE = 1e-5  #0.00001\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "NUM_EPOCHS = 100\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and save weight and log "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training process\n",
    "parameter base on DDPM paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nice/mambaforge/lib/python3.10/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Batch 984/984 Using Time: 252.2996            Loss: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:44,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] Batch 984/984 Using Time: 264.0821            Loss: 0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:48,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] Batch 984/984 Using Time: 266.6037            Loss: 0.0027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:49,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] Batch 984/984 Using Time: 267.6915            Loss: 0.0025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] Batch 984/984 Using Time: 267.9238            Loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:49,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] Batch 984/984 Using Time: 267.2298            Loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] Batch 984/984 Using Time: 267.8265            Loss: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] Batch 984/984 Using Time: 267.0831            Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:49,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] Batch 984/984 Using Time: 267.4691            Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] Batch 984/984 Using Time: 268.5200            Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:52,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] Batch 984/984 Using Time: 266.9136            Loss: 0.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:47,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] Batch 984/984 Using Time: 264.1223            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:47,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] Batch 984/984 Using Time: 264.2991            Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:47,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] Batch 984/984 Using Time: 264.2016            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:47,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] Batch 984/984 Using Time: 264.2225            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:48,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] Batch 984/984 Using Time: 266.6485            Loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:49,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] Batch 984/984 Using Time: 268.1866            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] Batch 984/984 Using Time: 267.0108            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:49,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] Batch 984/984 Using Time: 266.0725            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:48,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] Batch 984/984 Using Time: 266.0160            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] Batch 984/984 Using Time: 269.0245            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] Batch 984/984 Using Time: 274.4324            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:55,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] Batch 984/984 Using Time: 267.9397            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:49,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] Batch 984/984 Using Time: 265.5469            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:47,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] Batch 984/984 Using Time: 262.9820            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] Batch 984/984 Using Time: 262.2998            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] Batch 984/984 Using Time: 262.6237            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] Batch 984/984 Using Time: 261.5062            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] Batch 984/984 Using Time: 261.9300            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] Batch 984/984 Using Time: 261.5533            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] Batch 984/984 Using Time: 260.7541            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] Batch 984/984 Using Time: 260.4207            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] Batch 984/984 Using Time: 261.1978            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] Batch 984/984 Using Time: 260.8551            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] Batch 984/984 Using Time: 260.5156            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] Batch 984/984 Using Time: 260.6349            Loss: 0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] Batch 984/984 Using Time: 261.3359            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] Batch 984/984 Using Time: 261.3278            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] Batch 984/984 Using Time: 261.0544            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] Batch 984/984 Using Time: 261.7021            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] Batch 984/984 Using Time: 262.2472            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100] Batch 984/984 Using Time: 262.3739            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] Batch 984/984 Using Time: 261.0179            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100] Batch 984/984 Using Time: 260.6831            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100] Batch 984/984 Using Time: 260.6659            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100] Batch 984/984 Using Time: 260.6827            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100] Batch 984/984 Using Time: 261.1944            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100] Batch 984/984 Using Time: 261.4617            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100] Batch 984/984 Using Time: 261.5864            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100] Batch 984/984 Using Time: 262.0904            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:45,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100] Batch 984/984 Using Time: 262.0709            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100] Batch 984/984 Using Time: 261.7911            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100] Batch 984/984 Using Time: 262.1972            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100] Batch 984/984 Using Time: 262.4919            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100] Batch 984/984 Using Time: 262.4278            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100] Batch 984/984 Using Time: 262.6061            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100] Batch 984/984 Using Time: 262.9850            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:46,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100] Batch 984/984 Using Time: 265.9537            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100] Batch 984/984 Using Time: 267.9586            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:50,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100] Batch 984/984 Using Time: 268.3881            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:52,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100] Batch 984/984 Using Time: 271.0644            Loss: 0.0018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:53,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100] Batch 984/984 Using Time: 270.1576            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:51,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100] Batch 984/984 Using Time: 267.9355            Loss: 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:52,  5.78it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, images \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[0;32m---> 27\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     28\u001b[0m     t \u001b[39m=\u001b[39m diffusion\u001b[39m.\u001b[39msample_timesteps(images\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m     x_t, noise \u001b[39m=\u001b[39m diffusion\u001b[39m.\u001b[39mnoise_images(images, t)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = UNet().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "mse = nn.MSELoss()\n",
    "diffusion = Diffusion(img_size=IMAGE_SIZE, device=device)\n",
    "writer = SummaryWriter(os.path.join(\"logs/cats\",\"DDPM\"))\n",
    "\n",
    "l = len(data_loader)\n",
    "\n",
    "time_use = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    lossMean = 0\n",
    "\n",
    "    # use time for time measurement\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, images in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
    "        x_t, noise = diffusion.noise_images(images, t)\n",
    "        predicted_noise = model(x_t, t)\n",
    "        loss = mse(noise, predicted_noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # sum lose\n",
    "        lossMean += loss\n",
    "\n",
    "        # add log at first \n",
    "        if epoch == 0 and batch_idx == 0:\n",
    "            writer.add_scalar(\"MSE\", lossMean, global_step=epoch+1)\n",
    "            writer.add_scalar(\"traing time\", time_use, epoch_index)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    time_use += epoch_time \n",
    "\n",
    "    epoch_index = epoch+1\n",
    "\n",
    "    # calculate mean value\n",
    "    lossMean = lossMean / len(data_loader.dataset)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch_index}/{NUM_EPOCHS}] Batch {batch_idx+1}/{len(data_loader)} Using Time: {epoch_time:.4f}\\\n",
    "            Loss: {lossMean:.4f}\"\n",
    "    )\n",
    "\n",
    "    # tensorboard\n",
    "    writer.add_scalar(\"MSE\", lossMean, global_step=epoch+1)\n",
    "    writer.add_scalar(\"traing time\", time_use, epoch_index)\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(\"weights\", \"cats\", \"DDPM\", f\"{epoch_index}.pt\"))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = diffusion.sample(model, n=32).type(dtype=torch.float32)\n",
    "        img_grid = torchvision.utils.make_grid(x[:32], normalize=True)\n",
    "        writer.add_image(\"All/Generate Images\", img_grid, global_step=epoch_index)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure FID\n",
    "\n",
    "use this implementation: https://github.com/mseitzer/pytorch-fid/tree/master"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define FID measurement function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import re\n",
    "\n",
    "# Create a function to run the FID script\n",
    "def run_fid(real_path, gen_path, epoch):\n",
    "    command = [\"python\", \"-m\", \"pytorch_fid\", real_path, gen_path]\n",
    "\n",
    "    output = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Extract the FID score using regular expressions\n",
    "    output = output.stdout\n",
    "    fid_score_match = re.search(r\"FID:\\s+(\\d+\\.\\d+)\", output)\n",
    "    \n",
    "    if fid_score_match:\n",
    "        fid_score = float(fid_score_match.group(1))\n",
    "        print(\"FID score:\", fid_score)\n",
    "\n",
    "        # Write the FID score to the log file\n",
    "        # gen_log(log_path=\"logs/cats/fid/DCGAN.log\", message=f\"Epoch: {epoch}, FID score: {fid_score}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"FID score not found in the output.\")\n",
    "\n",
    "    return fid_score\n",
    "\n",
    "def FID_measure(model, sample_n=100*8, batch_size=8, device=\"cpu\", real_path=\"dataset/cats/\", gen_path=\"generated_images\", epoch=int):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Create a folder for generated images if it doesn't exist\n",
    "    os.makedirs(gen_path, exist_ok=True)\n",
    "    torch.manual_seed(2023)\n",
    "\n",
    "    # Generate images\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, sample_n, batch_size):\n",
    "            \n",
    "            x = diffusion.sample(model, n=batch_size).type(dtype=torch.float32)\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                save_image(x[j], f\"{gen_path}/{i+j}.png\", normalize=True)\n",
    "        \n",
    "    # Measure FID score between the real and generated images\n",
    "    fid_score = run_fid(real_path, gen_path, epoch)\n",
    "    return fid_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weight of model to measure FID score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weight( model, weight_path=\"\", index=int):\n",
    "\n",
    "    # Load the saved weights\n",
    "    model.load_state_dict(torch.load(f'{weight_path}/{index}.pt'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:38:55 - INFO: Sampling 64 new images....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [06:15,  2.66it/s]\n",
      "11:45:10 - INFO: Sampling 64 new images....\n",
      "563it [03:33,  2.64it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m load_weight(model, weight_path\u001b[39m=\u001b[39mdirectory_path, index\u001b[39m=\u001b[39mindex_weight)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m'\u001b[39m,index_weight)\n\u001b[0;32m---> 24\u001b[0m fid_score \u001b[39m=\u001b[39m FID_measure(model, sample_size, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, device\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mdevice\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, gen_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgen_image/cats/DDPM/\u001b[39;49m\u001b[39m{\u001b[39;49;00mindex_weight\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m, epoch\u001b[39m=\u001b[39;49mindex_weight)   \n\u001b[1;32m     26\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mMetrics/FID Score\u001b[39m\u001b[39m\"\u001b[39m, fid_score, index_weight)\n",
      "Cell \u001b[0;32mIn[43], line 40\u001b[0m, in \u001b[0;36mFID_measure\u001b[0;34m(model, sample_n, batch_size, device, real_path, gen_path, epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     38\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, sample_n, batch_size):\n\u001b[0;32m---> 40\u001b[0m         x \u001b[39m=\u001b[39m diffusion\u001b[39m.\u001b[39;49msample(model, n\u001b[39m=\u001b[39;49mbatch_size)\u001b[39m.\u001b[39mtype(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     42\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[1;32m     43\u001b[0m             save_image(x[j], \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mgen_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39mj\u001b[39m}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Workspace/Research/modules/ddpm.py:84\u001b[0m, in \u001b[0;36mDiffusion.sample\u001b[0;34m(self, model, n)\u001b[0m\n\u001b[1;32m     82\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn((n, \u001b[39m3\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_size))\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mreversed\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnoise_steps)), position\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m---> 84\u001b[0m     t \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39;49mones(n) \u001b[39m*\u001b[39;49m i)\u001b[39m.\u001b[39;49mlong()\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     85\u001b[0m     predicted_noise \u001b[39m=\u001b[39m model(x, t)\n\u001b[1;32m     86\u001b[0m     alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha[t][:, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'logs/cats/DDPM/')\n",
    "\n",
    "# Specify the directory path\n",
    "directory_path = Path('weights/cats/DDPM/')\n",
    "\n",
    "# Get the list of files ending with \".pth\"\n",
    "# file_list = list(directory_path.glob('*.pt'))\n",
    "\n",
    "\n",
    "model = UNet().to(device)\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    index_weight = i+1\n",
    "\n",
    "    load_weight(model, weight_path=directory_path, index=index_weight)\n",
    "\n",
    "    print('Epoch: ',index_weight)\n",
    "    fid_score = FID_measure(model, sample_size, batch_size=64, device=f\"{device}\", gen_path=f\"gen_image/cats/DDPM/{index_weight}/\", epoch=index_weight)   \n",
    "    \n",
    "    writer.add_scalar(\"Metrics/FID Score\", fid_score, index_weight)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count learnable parameter in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to(\"cuda\")\n",
    "\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22291587\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
